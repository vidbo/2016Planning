### Closed-Population Mark-Recapture Simulations

```{r setup, include=FALSE}
library(R2jags)
library(R2WinBUGS)
```

The goal is to estimate abundance of striped bass in the Salinas estuary between Hwy 1 and the coast, using mark-recapture methods. The fundamental constraint is the number of fish that can be sampled (captured, marked and released) in a day. The question is how many days of sampling will be required to get a reasonably constrained estimate.

At the Moss Landing meeting, it was thought that most stripers are concentrated in three areas, and that five hook-and-line samplers at each site could catch 25 fish at each site without impeding each other's success. Thus the fundamental constraint is 75 fish in a day, allocated more-or-less evenly across 3 sites. It was recommended that about a week should pass between sampling events, to allow the fish to get stupid again (stop being "trap shy," in scientific jargon).

The ability to make a good estimate is critically dependent on the number of marked fish that get recaptured, because it is these fish that allow one to estimate p, the probability of capture per fish per sampling event. Given an ability to capture a fixed number of fish per day, p will go down as population size (N) goes up (i.e. p = 75/N). Therefore I will simulate a series of different population sizes to get an idea of what sampling effort is required.

Below is code for a Bayesian mark-recapture model in the BUGS language. "Bayesian" is a common statistical framework that allows parameters (such as population size) to have probability distributions. The advantage here is that it is fairly easy to write a custom model that captures a particular situation. The key parts of the model below are: y[h,s] is the number of captured fish at site s with capture history h (history is a particular sequence of captures and non-captures over the sampling days). Us[s] is the number of uncaptured fish estimated for each site, and U is the estimate of total uncaptured fish. Population size is estimated simply by adding U to the total number of fish captured. 

Key assumptions are that each site is allowed to have its own p, but they are assumed to be similar to one another (drawn from a normal-logistic probability distribution). Other assumptions are that all fish are equally catchable at a site, they do not become trap shy (first capture probability and subsequent capture probability are the same), all fish occur at the three sites, and there is no gain or loss of fish from each site between capture sessions. It should be possible to relax some of these assumptions by adding additional complexities to the model, but it may require a more sophisticated sampling strategy. For now, applying the model to simulated data generated by the same assumptions should give an idea of how much sampling effort (number of days of sampling) will be required for a given population size.  

For completeness, here's the BUGS code for the model, but it is not necessary groc it.

```{r makemodel}
Nmod <- function(){
    # y[h,s] number of captured fish at site s with capture history h
    # S, H number of sites, unique histories
    # v[h, ] definitions of h histories, 1 = capture, 0 = no capture
    for (s in 1:S){    # sites
        for(h in 1:H)  { # number of unique capture histories
            y[h,s] ~ dpois (Ey[h,s])
            Ey[h,s] <- lambda[s] * exp(lp[h,s]) # lp = log probability
            lp[h,s] <- sum(v[h,]) * log(p[s]) + sum(1-v[h,]) * log(1-p[s]) # log-prob of capture history h
         }
    logit(p[s]) <- pp[s]
    pp[s] ~ dnorm(mu.p, tau.p)
    loglambda[s] ~ dunif(0, 8.111628)
    lambda[s] <- exp(loglambda[s])
    Eu[s] <- lambda[s] - sum(Ey[,s]) # expected number of uncaptured animals at site s
    Us[s] ~ dpois(Eu[s])
    }
    
    U <- sum(Us) # estimated number of uncaptured fish
    N <- U + sum(y)
    lam <- sum(lambda)
    mu.p ~ dnorm (0.0, 1.0E-6)
    tau.p <- pow(sigma.p, -2)
    sigma.p ~ dunif (0, 10)
}

write.model(Nmod, "Nmod.bug")

```

A key aspect of the Bayesian approach is that it is necessary to specify a prior guess at the range of population sizes that are plausible. Here I have assumed N is somewhere between 0 and 10000. The mark-recapture data are then used to further constrain the probability distribution of possible sizes. If the simulated data are not sufficient to constrain the possibilities, in the simulations you will see estimates widely scattered between 0 and 10000, indicating too few recaptures.

Now I will generate some simulated data. I will simulate population sizes ranging between 100 and 3000, numbers of capture events (days of sampling) from 2 to 7 events, 10 datasets for each combination.

```{r simulate}
N <- c(100, 350, 650, 1000, 1500, 2000, 2500, 3000) # set of true population sizes considered
cap <- 25  # number of fish captured per site per capture event
S <- 3  # number of sites
p <- (cap*S)/N  # probability of catching a fish, per event
E <- c(2,3,4,5,6,7) # numbers of capture events considered in simulation
iter <- 10  # number of times each type of dataset is simulated (replicates)

# if simulated data already exists, load it
if(file.exists("ClosedPopSims.RData") ) {
  load(file="ClosedPopSims.RData")
} else {
  # Otherwise, create simulated data
  sim.list <- list(NULL) # list of output
  j <- 0
  
  for(n in 1:length(N)) {
    for(e in 1:length(E)) {
      v <- expand.grid(rep(list(c(0,1)), E[e]))  # grid of all possible capture histories
      pmat <- v
      pmat[v==1] <- p[n]
      pmat[v==0] <- 1-p[n]
      pmat <- exp(rowSums(log(pmat))) # capture probs of each type of history
      smat <- rep(pmat, S) # capture probs of each history for S sites
      
      y <- rmultinom(n=iter, size=N[n], prob=smat)  # create random multinomial data
      u.vect <- 1 + length(pmat)*(0:(S-1)) # vector for rows of y that have completely uncaptured fish
      u <- y[u.vect,]  # simulated number of uncaptured fish (what we are trying to estimate)
      y <- y[-u.vect,] # removes rows of uncaptured fish
      y <- array(as.vector(y), dim=c(length(pmat)-1, S, iter))
      j <- j+1
      sim.list[[j]] <- list(N=N[n], S=S, E=E[e], y=y, u=sum(u), v=v[-1,], H=dim(v)[1]-1)
    }
  }
}

```

First let's test the model by applying it to 1 of the simulated datasets

```{r bugstest, results='hide'}
dat <- list(y=sim.list[[1]]$y[,,2], 
            S=sim.list[[1]]$S, H=sim.list[[1]]$H, v=sim.list[[1]]$v)

bugsmod <- jags(data=dat,
                parameters.to.save=c("U", "N", "p", "lam"),
                model.file="Nmod.bug")
```

Here is the output of the estimating procedure ("Markov-Chain Monte Carlo" aka MCMC), showing parameter estimates.
```{r bugstest2}
bugsmod
```

The "50%" column shows the median estimate of the parameter. The other percentiles columns give an idea of the uncertainty in the estimate, although we won't focus on them here. The "Rhat" should be close to 1 (i.e. <1.05); it is an indicator that the estimation procedure successfully did its job.

Since the test seems to work, I will now create parameter estimates for all the simulated data

```{r bugssumry}
if(file.exists("ClosedPopSims.RData") ) {
  load(file="ClosedPopSims.RData")
} else {
  # generate simulated data
  out <- NULL
  for(j in 1:length(sim.list)) {
    for(i in 1:iter ) {
  
      dat <- list(y=sim.list[[j]]$y[,,i], 
                S=sim.list[[j]]$S, H=sim.list[[j]]$H, v=sim.list[[j]]$v)
  
      bugsmod <- jags(data=dat,
                  parameters.to.save=c("U", "N", "p", "lam"),
                  model.file="Nmod.bug", n.iter=10000)
  
      out1 <- bugsmod$BUGSoutput$summary[1,]
      out <- rbind(out, c(E=sim.list[[j]]$E, N=sim.list[[j]]$N, out1))
    }
  }
}
save(out, sim.list, file="ClosedPopSims.RData")

```

Here are some graphs of the results. First column shows estimated population size as a function of true population size. Second column shows the number of recaptured fish (fish caught 2 or more times) as a function of true population size.


```{r fig.width=10, fig.height=16, echo=FALSE}

# compute number of fish with 2+ captures for each simulation
out2 <- NULL
for(i in 1:length(sim.list)) {
  y2 <- as.integer(rowSums(sim.list[[i]]$v) > 1) * sim.list[[i]]$y # recapture data with single captures zeroed out
  out2 <- rbind(out2, cbind(E=sim.list[[i]]$E, N=sim.list[[i]]$N, iter=1:10, multicapt=apply(y2, 3, FUN=sum)))
}

layout(t(matrix(1:12, ncol=6)))
par(mar=c(4,4,3,3))
# plot(dist_cats/1000, stress06[,1], type='l', ylim=c(0, 1), bty="n", lty=2,
#   	xlab="Distance downstream of Dam (km)", ylab="fraction of thermally stressful days",
# 		main="Year 2006")
# points(dist_cats/1000, stress06[,2], type='l', col="red")

for(this.E in E) {
  idx <- out[,1]==this.E # number of capture episodes
  plot(out[idx,2], out[idx,7], bty='n', xlab="Actual Population Size", ylab="Est. Size", main=paste(this.E, "Sampling Events"))
  points(c(100,3000),c(100,3000), type='l')
  
  plot(out[idx,2], out2[idx,4], bty='n', xlab="Actual Population Size", ylab="Recaptures")
}

```

The basic findings:

2 capture events can reliably deal with N up to at least 300

3 capture events, N up to at least 600, maybe 1000

4 capture events, N up to at least 1000

5 capture events, N up to 1000, perhaps 2000

6 capture events, N up to 1500, perhaps 2000

7 capture events, N up to 2500

The other way to look at what is required is the relative error (difference in % between estimated N and true N), as a function of the number of fish that were recaptured. Plotted below is relative error for different numbers of sampling events


```{r fig.width=7, fig.height=6, echo=FALSE}


layout(t(matrix(1:6, ncol=2)))
par(mar=c(4,4,3,3))
# plot(dist_cats/1000, stress06[,1], type='l', ylim=c(0, 1), bty="n", lty=2,
#     xlab="Distance downstream of Dam (km)", ylab="fraction of thermally stressful days",
# 		main="Year 2006")
# points(dist_cats/1000, stress06[,2], type='l', col="red")

for(this.E in E) {
  idx <- out[,1]==this.E # number of capture episodes
  # relative error of estimate as function of number of recaptures
  plot(out2[idx,4], 100*(out[idx,7]-out[idx,2])/out[idx,2], bty='n', 
       ylim=c(-50, 200), 
       xlab="Recaptures", ylab="% Error", main=paste(this.E, "Sampling Events"),
       pch=as.integer(as.factor(out[idx,2])))
  # reference lines
  points(c(0,150),c(30,30), type='l', lty=3)
  points(c(0,150),c(-30,-30), type='l', lty=3)
  points(c(30,30),c(-50,200), type='l', lty=3)

  if(this.E==2) legend("topright", legend=unique(out[idx,2]), pch=1:8, title="Pop. Size")
}






```

These plots suggest that to get relative error within the bounds of 30% (the horizontal dotted lines), it should generally suffice if you get 30 recaptured fish. Of course, to get this you have to catch a lot more fish if the population is 3000 bass than if it is 350.

- David Boughton



